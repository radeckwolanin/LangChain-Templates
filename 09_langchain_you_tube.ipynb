{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube - summary generator\n",
    "Use YT videos transcript and summarize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Obtaining dependency information for youtube-transcript-api from https://files.pythonhosted.org/packages/33/c1/18e32c7cd693802056f385c3ee78825102566be94a811b6556f17783c743/youtube_transcript_api-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests in /home/azureuser/miniconda3/envs/RemoteEnv/lib/python3.8/site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/azureuser/miniconda3/envs/RemoteEnv/lib/python3.8/site-packages (from requests->youtube-transcript-api) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azureuser/miniconda3/envs/RemoteEnv/lib/python3.8/site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/azureuser/miniconda3/envs/RemoteEnv/lib/python3.8/site-packages (from requests->youtube-transcript-api) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azureuser/miniconda3/envs/RemoteEnv/lib/python3.8/site-packages (from requests->youtube-transcript-api) (2023.7.22)\n",
      "Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.6.1\n",
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install youtube-transcript-api\n",
    "! pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # Load environment variables from .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") # Get API key from environment variable\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__7fe96d9dfa664e99ad0e78c2f9302178\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"youtube_template\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Simple Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=pNcQ5XXMgH4\", add_video_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Found video from Greg Kamradt (Data Indy) that is 668 seconds long\n",
      "{'source': 'pNcQ5XXMgH4', 'title': 'LangChain 101: YouTube Transcripts + OpenAI', 'description': 'Unknown', 'view_count': 17761, 'thumbnail_url': 'https://i.ytimg.com/vi/pNcQ5XXMgH4/hqdefault.jpg?sqp=-oaymwEXCJADEOABSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCmP9TXvB4nm22ZX7b5Tl0AagEU3A', 'publish_date': '2023-02-23 00:00:00', 'length': 668, 'author': 'Greg Kamradt (Data Indy)'}\n",
      "\n",
      "[Document(page_content=\"what is going on good people again right now we have a super exciting tutorial because we are going to take YouTube transcripts and we're going to pass them to open Ai and the way that we're going to do that is via a library called Lang chain which is what this entire series is about now before we jumped into it I wanted to show a diagram again I think these diagrams are helpful but you have to let me know so just let me know in the comments here so I wanted to do an overview about what we're actually going to be writing out in code because I think it's a little easier to see in pictures first so the way this is going to work is we're going to have a video a YouTube video we're going to pass it we're going to pass it a URL and then what Lang chain is going to help us do is it's going to help us load this video as a document and a document just means you're going to be taking the transcript which is the text of the video and you're going to be loading it as a document which is something that lane chain can help understand now with that document we're then going to go generate a summary of it and the way that link chain is going to do this is it's going to create a prompt for us that says hey generate me a concise summary of the following text and then it's going insert the transcript of the YouTube video which is pretty sweet and this is going to happen in open Ai and this is going to happen to be an API call and then what we get out the other end is open AI is going to tell us hey this video is about XYZ now an interesting part about this and where it gets kind of confusing is well what happens if your video is too long oh no our video two is too long we can't pass this because say you're looking at a YouTube video and it's like an hour long well you can't pass all that transcript into open AI because they have a token limit and this is where a lot of the ergonomics of Lang chain really come to help out here now what we're going to do is we're actually going to split up that text so we're going to still see that it's from video two but we're going to have our document one document two document three and then what Lang chain is going to help us do is it's going to go to open Ai and it's going to say hey I want you to generate a summary for me of document one generate of document 2 generate of document three now the cool part about this is that this is all under the hood the cool part is then what it's going to do is it's going to say hey please generate me a summary of these summaries and then all of a sudden open AI is going to give us a summary of the summaries and the conclusion you get with the video is all the way about now this is one method of kind of combining documents like this and this is called the map reduce method but we'll get into that in a second when we talk about the different chain types all right that's enough diagrams let's look at some code here all right now that we're looking at some code here our first import statements uh this the star of the show here is going to be the YouTube loader this is going to be the tool that is going to help us do this we're going to uh import open Ai and we're going to import load summarize chain because this is going to be the chain that's going to help summarize for us so let's go ahead and run those I also had to install YouTube's transcripts API and then also pytube as well in case you uh run on that same problem so with the YouTube loader we're going to call Dot from YouTube URL and we are going to pass it a single YouTube url here and what that'll do is we're going to store that in a loader so to get it ready and kind of stage it and then we're actually going to call Dot load on it which is going to do the loading for us and I wanted to print this out and show you what we have here so if we have if we look at this result you can see that the result is a list of items it's very important we'll talk about this in a second year and then we just have some metadata on it but it is going to be a list of documents and these are the things that lane chain can help understand and can process for us and in this document you can see here that there's a page context which is going to be the transcript that is from this video and then we also have some interesting metadata too about the video itself but I'm going to go ahead and close this here we're going to uh instantially oh I want I need to load the open AI key we're going to initialize our large language model which is going to be the open AI one and then we're going to call load summarize chain we're going to pass it our model we're going to say chain type equals stuff important here we're going to talk about why this is changing later we're going to say verbose equals false because we don't want to see anything and then we're going to pass it the result that we loaded in which is the the document or the list of documents that we had let's go ahead and run this and then all of a sudden we get cool Pedro Pascal shared his experiences shooting HBO's Last of Us awesome so just based off the transcript it has a some summary of the YouTube video for us nice but what if you have a long video so I wanted to show you this one here we have another YouTube video which is going to be a podcast of my first million on here we hear some Sean talk and you can see that it is going to be almost 60 Minutes long and this is quite long and spoiler alert it's too long for open AI uh for the token limit that they have so let me show you this though we're going to load this in we're going to load the result you can see it takes a little bit and then we're going to say load summarize chain okay cool with chain type equals stuff and we're going to run this result here and then oh no we have an error it's trying to do something up here and it says this model's maximum context is uh 4097 tokens you've requested almost fifteen thousand and that's no good because that's too long so in the old days before Lang chain what we'd have to do here is we'd have to figure out some way to either run multiple pieces ourselves manually copy and paste it'd be a freaking mess we don't want to do any of that stuff so the problem is your transcript or your document is too long now what we're going to do here is we're actually going to split up that document which is what we saw earlier on the diagram and so I'm going to load in the recursive character splitter and I'm going to get this loaded here and I'm just going to set a chunk size of 2000. you can play with this it might be different for your use case whatever you want but if you're not getting what you need try switching this variable if you want some help there I'm going to load up that text footer and now what I'm going to do is I'm going to load in that single YouTube video into the text splitter and what it's going to do for me is actually I want to show you this here uh text and so let's let's first check out the type of text it is going to be a list okay cool let's see what it's a list of and you can see here it's a list of documents and this page context is still quite long but it's we're aiming for a chunk size of about 2 000. I just want to show you what a chunk size of 100 would look like and so we have a a list of documents again with a page context and this page context is only about a hundred characters long ish or 100 tokens long-ish it's it's uh it's interesting there and so if we were to look at no I don't want to do type I want to do length so if we're to do length of how many texts we have we have 522 and that's because it's taking our entire transcript and it's basically putting it into chunks roughly of a of a hundred if we're to do a thousand for chunks you can see here it's roughly 10 times less which is going to be on the 51. so this is a way to split up your documents and so now we have a whole bunch of documents um that are length of what we set right here but I'm going to set this back to 2000. nice and then what we're going to do is I'm going to call the llm here but I'm going to change the chain type and in fact before we did this I want to I want to show you the issue here um let's do chunk size 2000 and then we're going to do stuff and I'm going to call run and let's do oh I want to do this on text let's do run right here and so the issue is that we have again this is the maximum model length but we've requested all these documents together because when you do chain type equals stuff what you're doing is you're saying the Lang chain hey I want you to take all my documents and stuff them into the prompt that you're feeding open AI now there's a way around this not a way around this but an alternative is if you change the type to mapreduce that is when you're going to start to say hey just give me a summary of all these different documents that you have and then generate me a final summary so if we change it to mapreduce I'm going to go ahead and run this and let's give this a sec because this is going to make multiple API calls because what it's actually doing is it's making a uh it's telling hey open AI I want you to give me a summary of each one of these different documents and you saw how we had quite a uh a few number of documents cool well nice so we just had this long transcript and what we just had is now we have the summary of what this transcript says but I wanted to show you what it this actually looks like underneath the covers of what um Lang chain is doing and so what I'm going to do here is I'm going to set for both equals true which gives you insight as to the calls that laying chain is making the open AI this is going to get kind of confusing so I just want to do the first four documents on here which is you know the first little bit of the video that we loaded and so what we're going to look at here is we're going to look at all right we're doing a mapreduce document chain cool and so the very first call that it's saying to open AI is write me a concise summary of The Following nice so here is the following statement and this is one of the document chunks that we submitted beforehand and then it's saying hey again I want you to write me a concise summary of the following now here's the second document that we wanted it to summarize and then here's the third document and then here's the fourth document now the cool part is what you can see that gets returned is we have four different summaries of four different documents so summary One summary two summary three and summary four and the reason why is because we just wanted to see the first four that we had up here so we have all those summaries and then what it said was is basically write me a concise summary of the following so a summary of the summaries and then what we get is we get this uh summary of the summaries that's right here nice um it's cool now what if you have multiple videos that you want to do well in this case I have a YouTube url list I'm just passing it two different videos I'm going to get a list ready that is going to hold my text for me I'm going to get my uh character splitter ready and I'm going to say hey for URL in this list of URLs I want you to load up the video or get the loader ready I want you to load the video and then I want you to extend this list with the documents that you've split it into so in this case I have two YouTube videos I'm just going to go through both of them right there and then I'm going to call the summarize scan again with mapreduce in this case I don't really want to do verbose equals true because you already saw what that looked like but now what it's doing is it's going through both those videos it's split it splitting them up into separate documents in case that they're in case they're too long and then it's generating a summary for me now these were two videos about two completely different things and so this it starts off with a golf video about how to build a golf course in your backyard so it says cool blah blah looks great and then now it goes into the second summary which is around uh a uh interview between Bella Ramsay and Pedro Pascal about what they were doing so that is how you do uh loading up YouTube videos with a transcript and with the summaries I hope that that was helpful for you please let me know if the diagram was helpful I'm happy to do more videos and as always please leave please leave comments about how we can improve the videos and about your own personal uh business problems that we can help solve I'll see you later\", metadata={'source': 'pNcQ5XXMgH4', 'title': 'LangChain 101: YouTube Transcripts + OpenAI', 'description': 'Unknown', 'view_count': 17761, 'thumbnail_url': 'https://i.ytimg.com/vi/pNcQ5XXMgH4/hqdefault.jpg?sqp=-oaymwEXCJADEOABSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCmP9TXvB4nm22ZX7b5Tl0AagEU3A', 'publish_date': '2023-02-23 00:00:00', 'length': 668, 'author': 'Greg Kamradt (Data Indy)'})]\n"
     ]
    }
   ],
   "source": [
    "print (type(result))\n",
    "print (f\"Found video from {result[0].metadata['author']} that is {result[0].metadata['length']} seconds long\")\n",
    "print(result[0].metadata)\n",
    "print (\"\")\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This tutorial explains how to use the Lang Chain library to take YouTube transcripts and pass them to Open AI to generate a summary. It also explains how to use the recursive character splitter to split up long transcripts into smaller chunks, and how to use the mapreduce method to generate a summary of multiple videos. Finally, it explains how to use the summarize scan to generate a summary of multiple videos.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", verbose=False)\n",
    "chain.run(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Long Video (use map-reduce)\n",
    "\n",
    "    When video is too long, it will not fit into context window. Use map-reduce chain using chanks of transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"what is going on good people again right now we have a super exciting tutorial because we are going to take YouTube transcripts and we're going to pass them to open Ai and the way that we're going to do that is via a library called Lang chain which is what this entire series is about now before we jumped into it I wanted to show a diagram again I think these diagrams are helpful but you have to let me know so just let me know in the comments here so I wanted to do an overview about what we're actually going to be writing out in code because I think it's a little easier to see in pictures first so the way this is going to work is we're going to have a video a YouTube video we're going to pass it we're going to pass it a URL and then what Lang chain is going to help us do is it's going to help us load this video as a document and a document just means you're going to be taking the transcript which is the text of the video and you're going to be loading it as a document which is something\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"to be loading it as a document which is something that lane chain can help understand now with that document we're then going to go generate a summary of it and the way that link chain is going to do this is it's going to create a prompt for us that says hey generate me a concise summary of the following text and then it's going insert the transcript of the YouTube video which is pretty sweet and this is going to happen in open Ai and this is going to happen to be an API call and then what we get out the other end is open AI is going to tell us hey this video is about XYZ now an interesting part about this and where it gets kind of confusing is well what happens if your video is too long oh no our video two is too long we can't pass this because say you're looking at a YouTube video and it's like an hour long well you can't pass all that transcript into open AI because they have a token limit and this is where a lot of the ergonomics of Lang chain really come to help out here now what\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Lang chain really come to help out here now what we're going to do is we're actually going to split up that text so we're going to still see that it's from video two but we're going to have our document one document two document three and then what Lang chain is going to help us do is it's going to go to open Ai and it's going to say hey I want you to generate a summary for me of document one generate of document 2 generate of document three now the cool part about this is that this is all under the hood the cool part is then what it's going to do is it's going to say hey please generate me a summary of these summaries and then all of a sudden open AI is going to give us a summary of the summaries and the conclusion you get with the video is all the way about now this is one method of kind of combining documents like this and this is called the map reduce method but we'll get into that in a second when we talk about the different chain types all right that's enough diagrams let's look\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"types all right that's enough diagrams let's look at some code here all right now that we're looking at some code here our first import statements uh this the star of the show here is going to be the YouTube loader this is going to be the tool that is going to help us do this we're going to uh import open Ai and we're going to import load summarize chain because this is going to be the chain that's going to help summarize for us so let's go ahead and run those I also had to install YouTube's transcripts API and then also pytube as well in case you uh run on that same problem so with the YouTube loader we're going to call Dot from YouTube URL and we are going to pass it a single YouTube url here and what that'll do is we're going to store that in a loader so to get it ready and kind of stage it and then we're actually going to call Dot load on it which is going to do the loading for us and I wanted to print this out and show you what we have here so if we have if we look at this result\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"have here so if we have if we look at this result you can see that the result is a list of items it's very important we'll talk about this in a second year and then we just have some metadata on it but it is going to be a list of documents and these are the things that lane chain can help understand and can process for us and in this document you can see here that there's a page context which is going to be the transcript that is from this video and then we also have some interesting metadata too about the video itself but I'm going to go ahead and close this here we're going to uh instantially oh I want I need to load the open AI key we're going to initialize our large language model which is going to be the open AI one and then we're going to call load summarize chain we're going to pass it our model we're going to say chain type equals stuff important here we're going to talk about why this is changing later we're going to say verbose equals false because we don't want to see\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"verbose equals false because we don't want to see anything and then we're going to pass it the result that we loaded in which is the the document or the list of documents that we had let's go ahead and run this and then all of a sudden we get cool Pedro Pascal shared his experiences shooting HBO's Last of Us awesome so just based off the transcript it has a some summary of the YouTube video for us nice but what if you have a long video so I wanted to show you this one here we have another YouTube video which is going to be a podcast of my first million on here we hear some Sean talk and you can see that it is going to be almost 60 Minutes long and this is quite long and spoiler alert it's too long for open AI uh for the token limit that they have so let me show you this though we're going to load this in we're going to load the result you can see it takes a little bit and then we're going to say load summarize chain okay cool with chain type equals stuff and we're going to run this\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"type equals stuff and we're going to run this result here and then oh no we have an error it's trying to do something up here and it says this model's maximum context is uh 4097 tokens you've requested almost fifteen thousand and that's no good because that's too long so in the old days before Lang chain what we'd have to do here is we'd have to figure out some way to either run multiple pieces ourselves manually copy and paste it'd be a freaking mess we don't want to do any of that stuff so the problem is your transcript or your document is too long now what we're going to do here is we're actually going to split up that document which is what we saw earlier on the diagram and so I'm going to load in the recursive character splitter and I'm going to get this loaded here and I'm just going to set a chunk size of 2000. you can play with this it might be different for your use case whatever you want but if you're not getting what you need try switching this variable if you want some\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"need try switching this variable if you want some help there I'm going to load up that text footer and now what I'm going to do is I'm going to load in that single YouTube video into the text splitter and what it's going to do for me is actually I want to show you this here uh text and so let's let's first check out the type of text it is going to be a list okay cool let's see what it's a list of and you can see here it's a list of documents and this page context is still quite long but it's we're aiming for a chunk size of about 2 000. I just want to show you what a chunk size of 100 would look like and so we have a a list of documents again with a page context and this page context is only about a hundred characters long ish or 100 tokens long-ish it's it's uh it's interesting there and so if we were to look at no I don't want to do type I want to do length so if we're to do length of how many texts we have we have 522 and that's because it's taking our entire transcript and it's\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"it's taking our entire transcript and it's basically putting it into chunks roughly of a of a hundred if we're to do a thousand for chunks you can see here it's roughly 10 times less which is going to be on the 51. so this is a way to split up your documents and so now we have a whole bunch of documents um that are length of what we set right here but I'm going to set this back to 2000. nice and then what we're going to do is I'm going to call the llm here but I'm going to change the chain type and in fact before we did this I want to I want to show you the issue here um let's do chunk size 2000 and then we're going to do stuff and I'm going to call run and let's do oh I want to do this on text let's do run right here and so the issue is that we have again this is the maximum model length but we've requested all these documents together because when you do chain type equals stuff what you're doing is you're saying the Lang chain hey I want you to take all my documents and stuff them\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"want you to take all my documents and stuff them into the prompt that you're feeding open AI now there's a way around this not a way around this but an alternative is if you change the type to mapreduce that is when you're going to start to say hey just give me a summary of all these different documents that you have and then generate me a final summary so if we change it to mapreduce I'm going to go ahead and run this and let's give this a sec because this is going to make multiple API calls because what it's actually doing is it's making a uh it's telling hey open AI I want you to give me a summary of each one of these different documents and you saw how we had quite a uh a few number of documents cool well nice so we just had this long transcript and what we just had is now we have the summary of what this transcript says but I wanted to show you what it this actually looks like underneath the covers of what um Lang chain is doing and so what I'm going to do here is I'm going to\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"and so what I'm going to do here is I'm going to set for both equals true which gives you insight as to the calls that laying chain is making the open AI this is going to get kind of confusing so I just want to do the first four documents on here which is you know the first little bit of the video that we loaded and so what we're going to look at here is we're going to look at all right we're doing a mapreduce document chain cool and so the very first call that it's saying to open AI is write me a concise summary of The Following nice so here is the following statement and this is one of the document chunks that we submitted beforehand and then it's saying hey again I want you to write me a concise summary of the following now here's the second document that we wanted it to summarize and then here's the third document and then here's the fourth document now the cool part is what you can see that gets returned is we have four different summaries of four different documents so summary\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"summaries of four different documents so summary One summary two summary three and summary four and the reason why is because we just wanted to see the first four that we had up here so we have all those summaries and then what it said was is basically write me a concise summary of the following so a summary of the summaries and then what we get is we get this uh summary of the summaries that's right here nice um it's cool now what if you have multiple videos that you want to do well in this case I have a YouTube url list I'm just passing it two different videos I'm going to get a list ready that is going to hold my text for me I'm going to get my uh character splitter ready and I'm going to say hey for URL in this list of URLs I want you to load up the video or get the loader ready I want you to load the video and then I want you to extend this list with the documents that you've split it into so in this case I have two YouTube videos I'm just going to go through both of them right\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"I'm just going to go through both of them right there and then I'm going to call the summarize scan again with mapreduce in this case I don't really want to do verbose equals true because you already saw what that looked like but now what it's doing is it's going through both those videos it's split it splitting them up into separate documents in case that they're in case they're too long and then it's generating a summary for me now these were two videos about two completely different things and so this it starts off with a golf video about how to build a golf course in your backyard so it says cool blah blah looks great and then now it goes into the second summary which is around uh a uh interview between Bella Ramsay and Pedro Pascal about what they were doing so that is how you do uh loading up YouTube videos with a transcript and with the summaries I hope that that was helpful for you please let me know if the diagram was helpful I'm happy to do more videos and as always please\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"I'm happy to do more videos and as always please leave please leave comments about how we can improve the videos and about your own personal uh business problems that we can help solve I'll see you later\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" In this tutorial, we will be using the Lang Chain library to take YouTube transcripts and pass them to Open AI. We will be using a diagram to help visualize the code we will be writing. We will be taking a YouTube video URL and loading the transcript as a document.\n",
      "\n",
      " Lang Chain is a tool that can help generate a summary of a document by creating a prompt and using Open AI to generate a summary. It is useful for summarizing long documents, such as YouTube videos, as it has a token limit. Lang Chain's ergonomics help to make this process easier.\n",
      "\n",
      " Lang chain is a tool that can be used to split up text and generate summaries of documents. It uses Open AI to generate a summary of the summaries, which is called the map reduce method. This is one method of combining documents.\n",
      "\n",
      " This code is using the YouTube Loader to import OpenAI and Load Summarize Chain to help summarize a single YouTube URL. It also requires the installation of YouTube's Transcripts API and PyTube. The code will store the URL in a loader, and then call .load on it to do the loading. The result of this will be printed out.\n",
      "\n",
      " This result is a list of documents that can be processed by Lane Chain. It includes page context from a video and metadata about the video. The Open AI key is loaded and a large language model is initialized. The summarize chain is called and the chain type is set to \"stuff important\" and verbose is set to false.\n",
      "\n",
      " This article discusses how to use Open AI to summarize a YouTube video. It explains how to set verbose to false and pass the result of the loaded document. It then provides an example of a long video and how to use the summarize chain to summarize it.\n",
      "\n",
      " This text discusses a problem with a model's maximum context being too long for a given document. To solve this problem, the document must be split up into smaller chunks. The chunk size can be adjusted depending on the use case.\n",
      "\n",
      " This text is about loading a YouTube video into a text splitter and seeing what a chunk size of 100 would look like. The page context is about 100 characters long and the length of the text is 522.\n",
      "\n",
      " This is a process of splitting up a transcript into chunks of roughly 100 words. The chunk size can be adjusted to 2000 words. The process involves calling the Lang chain and setting the chain type to \"stuff\" which will take all the documents and stuff them together.\n",
      "\n",
      " This text explains how to use Open AI to generate a summary of multiple documents by changing the type to mapreduce. It also shows what the process looks like underneath the covers of Lang Chain.\n",
      "\n",
      " This statement explains how to use Open AI to create a mapreduce document chain. It will take four documents and return four different summaries of each document.\n",
      "\n",
      " This text describes a process for summarizing multiple videos by creating a list of URLs, loading the videos, and splitting the documents into summaries. The summaries are then combined into one concise summary.\n",
      "\n",
      " This video explains how to use mapreduce to generate summaries for two different videos. The first video is about building a golf course in your backyard, and the second is an interview between Bella Ramsay and Pedro Pascal. The video also provides a diagram to help viewers understand the process.\n",
      "\n",
      " The speaker is offering to do more videos and encourages viewers to leave comments about how the videos can be improved and about their own business problems that the speaker can help solve.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' This tutorial explains how to use Open AI and Lang Chain to generate summaries of multiple documents, such as YouTube videos. It provides a diagram to help visualize the code and explains how to use the mapreduce method to combine documents into one concise summary. The speaker also encourages viewers to leave comments about how the videos can be improved and about their own business problems.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(texts)\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multiple Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url_list = [\"https://www.youtube.com/watch?v=UfL7hqGBLAQ\", \"https://www.youtube.com/watch?v=9z7p28FhoEc\"]\n",
    "\n",
    "texts = []\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "\n",
    "for url in youtube_url_list:\n",
    "    loader = YoutubeLoader.from_youtube_url(url, add_video_info=True)\n",
    "    result = loader.load()\n",
    "    \n",
    "    texts.extend(text_splitter.split_documents(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Congressman Elise Stefanik of New York's 21st Congressional District is supportive of the impeachment inquiry into President Biden and is committed to helping re-elect President Trump in 2024. A search and rescue operation is underway in Morocco following a devastating earthquake that killed 2,900 people and left hundreds of thousands homeless. International search and rescue teams have been invited by the Moroccan military to the town of Amiz, and volunteers, family, friends, local charities, and NOS are helping people in the mountains. There has been criticism that other international agencies and countries have not been able to get into Morocco.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=False)\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
